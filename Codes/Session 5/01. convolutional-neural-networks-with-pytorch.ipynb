{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf7301e-a026-4b68-b5ca-4265e8bf2d59",
   "metadata": {},
   "source": [
    "## How ConvNets are used for Computer Vision\n",
    "\n",
    "If you are new to the world of neural networks, you will likely see such networks being displayed as a set of connected neurons:\n",
    "\n",
    "![](images/Basic-neural-network.jpg)\n",
    "\n",
    "These networks are called _Multilayer Perceptrons_, or MLPs for short. They take some input data, pass them through (a set of) layers in a forward fashion, and then generate a prediction in some output layer.\n",
    "\n",
    "With MLPs, a variety of problems can be solved - including computer vision problems. But this does not mean that they are the best tool for the job. Rather, it is more likely that you will be using a **Convolutional Neural Network** - which looks as follows:\n",
    "\n",
    "![](images/convnet_fig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f593ee3-a116-40e0-97ff-0e9098466e91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A ConvNet, structured\n",
    "\n",
    "Let's now take a look at the image above. We begin on the right, where you'll see an _Outputs_ layer with two outputs. Apparently, that network generates two types of predictions (for example, it can be a multiclass network with two classes, or it can give two regression outputs).\n",
    "\n",
    "Left of this layer, we can see two layers with Hidden units. These are called _Fully connected_. Indeed, they are the type of layer that we know from a Multilayer Perceptron! In other words, a Convolutional Neural Network often includes a MLP for generating the predictions. But then what makes such a network _Convolutional?_\n",
    "\n",
    "On the left, we can see so-called **Convolution** layers followed by (Max) pooling] layers. \n",
    "\n",
    "A Convolutional layer combines two parts and generates a function that expresses how one alters the other. Recall, if you are familiar with neural networks, that they have _inputs_ which are fed through a layer that has _weights_. If you take a look at this from a Convolution perspective, such a layer will have weights - and it evaluates how much inputs \"alter\", or \"trigger\" these weights.\n",
    "\n",
    "Then, by adapting the weights during optimization, we can teach the network to be \"triggered\" by certain patterns present in the input data. Indeed, such layers can be taught to be triggered by certain parts that are present in some input data, such as a nose, and relate it to e.g. output class \"human\" (when seen from the whoel network).\n",
    "\n",
    "Since Convnets work with a kernel that is slided over the input data, they are said to be _translation invariant_ - meaning that a nose can be detected regardless of size and position within the image. It is why ConvNets are way more powerful for computer vision problems than classic MLPs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d45a25-4df4-463d-acab-d8eb5d527450",
   "metadata": {},
   "source": [
    "## Code example: simple Convolutional Neural Network with PyTorch\n",
    "\n",
    "Now that we have recalled how ConvNets work, it's time to actually build one with PyTorch. Next, you will see a full example of a simple Convolutional Neural Network. From beginning to end, you will see that the following happens:\n",
    "\n",
    "1. **The imports**. First of all, we're importing all the dependencies that are necessary for this example. For loading the dataset, which is `MNIST`, we'll need the operating system functionalities provided by Python - i.e., `os`. We'll also need PyTorch (`torch`) and its neural networks library (`nn`). Using the `DataLoader` we can load the dataset, which we can transform into Tensor format with `transforms` - as we will see later.\n",
    "2. **The neural network Module definition.** In Pytorch, neural networks are constructed as `nn.Module` instances - or neural network modules. In this case, we specify a `class` called `ConvNet`, which extends the `nn.Module` class. In its constructor, we pass some data to the super class, and define a `Sequential` set of layers. This set of layers means that a variety of neural network layers is stacked on top of each other.\n",
    "3. **The layers**. Recall from the image above that the first layers are Convolutional in nature, followed by MLP layers. For two-dimensional inputs, such as images, Convolutional layers are represented in PyTorch as `nn.Conv2d`. Recall that all layers require an activation function, and in this case we use Rectified Linear Unit (`ReLU`). The multidimensional output of the final Conv layer is flattened into one-dimensional inputs for the MLP layers, which are represented by `Linear` layers.\n",
    "4. **Layer inputs and outputs.** All Python layers represent the number of _in\\_channels_ and the number of _out\\_channels_ in their first two arguments, if applicable. For our example, this means that:\n",
    "    - The first `Conv2d` layer has one input channel (which makes sence, since MNIST data is grayscale and hence has one input channel) and provides ten output channels.\n",
    "    - The second `Conv2d` layer takes these ten output channels and outputs five.\n",
    "    - As the MNIST dataset has 28 x 28 pixel images, two `Conv2d` layers with a kernel size of 3 produce feature maps of 24 x 24 pixels each. This is why after flattening, our number of inputs will be `24 * 24 * 5` - 24 x 24 pixels with 5 channels from the Conv layer. 64 outputs are specified.\n",
    "    - The next Linear layer has 64 inputs and 32 outputs.\n",
    "    - Finally, the 32 inputs are converted into 10 outputs. This also makes sence, since MNIST has ten classes (the numbers 0 to 9). Our loss function will be able to handle this format.\n",
    "5. **Forward definition**. In the `forward` def, the forward pass of the data through the network is performed.\n",
    "6. **The operational aspects**. Under the `main` check, the random seed is fixed, the data is loaded and preprocessed, the ConvNet, loss function and optimizer are initialized and the training loop is performed. In the training loop, batches of data are passed through the network, after the loss is computed and the error is backpropagated, after which the network weights are adapted during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6238bc64-aeea-4e18-8aa1-8cb305aef2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d89017-9ef4-49a5-8390-456d9d9c8a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    '''\n",
    "    Simple Convolutional Neural Network\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 5, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(24 * 24 * 5, 64),     \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfd8bab3-5c31-48e7-b682-8affa547797e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 26, 26]             100\n",
      "              ReLU-2           [-1, 10, 26, 26]               0\n",
      "            Conv2d-3            [-1, 5, 24, 24]             455\n",
      "              ReLU-4            [-1, 5, 24, 24]               0\n",
      "           Flatten-5                 [-1, 2880]               0\n",
      "            Linear-6                   [-1, 64]         184,384\n",
      "              ReLU-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,080\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 187,349\n",
      "Trainable params: 187,349\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.17\n",
      "Params size (MB): 0.71\n",
      "Estimated Total Size (MB): 0.89\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "convnet = ConvNet()\n",
    "print(summary(convnet, (1, 28, 28), device = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769267e4-1915-4f74-8b08-772f62282c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_of_input_channels=1, num_of_classes=10, dropout_prob=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Using nn.Sequential for Convolutional layers\n",
    "        self.layers = nn.Sequential(\n",
    "            # Conv layer 1\n",
    "            nn.Conv2d(num_of_input_channels, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv layer 4\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(128, num_of_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0f62b2d-90a1-4079-aad5-19b3c73ff576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "         MaxPool2d-3           [-1, 32, 13, 13]               0\n",
      "            Conv2d-4           [-1, 64, 11, 11]          18,496\n",
      "              ReLU-5           [-1, 64, 11, 11]               0\n",
      "         MaxPool2d-6             [-1, 64, 5, 5]               0\n",
      "            Conv2d-7            [-1, 128, 5, 5]          73,856\n",
      "              ReLU-8            [-1, 128, 5, 5]               0\n",
      "         MaxPool2d-9            [-1, 128, 2, 2]               0\n",
      "           Conv2d-10             [-1, 64, 2, 2]          73,792\n",
      "             ReLU-11             [-1, 64, 2, 2]               0\n",
      "        MaxPool2d-12             [-1, 64, 1, 1]               0\n",
      "          Flatten-13                   [-1, 64]               0\n",
      "           Linear-14                  [-1, 128]           8,320\n",
      "             ReLU-15                  [-1, 128]               0\n",
      "          Dropout-16                  [-1, 128]               0\n",
      "           Linear-17                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 176,074\n",
      "Trainable params: 176,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.56\n",
      "Params size (MB): 0.67\n",
      "Estimated Total Size (MB): 1.24\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "convnet = ConvNet2()\n",
    "print(summary(convnet, (1, 28, 28), device = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "028b8e8f-8401-481c-9419-c5a2fcae5c24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.400320\n",
      "Loss after mini-batch  1000: 0.464280\n",
      "Loss after mini-batch  1500: 0.380416\n",
      "Loss after mini-batch  2000: 0.341173\n",
      "Loss after mini-batch  2500: 0.347730\n",
      "Loss after mini-batch  3000: 0.309481\n",
      "Loss after mini-batch  3500: 0.306106\n",
      "Loss after mini-batch  4000: 0.289833\n",
      "Loss after mini-batch  4500: 0.275308\n",
      "Loss after mini-batch  5000: 0.246124\n",
      "Loss after mini-batch  5500: 0.244529\n",
      "Loss after mini-batch  6000: 0.223712\n",
      "Starting epoch 2\n",
      "Loss after mini-batch   500: 0.216508\n",
      "Loss after mini-batch  1000: 0.226549\n",
      "Loss after mini-batch  1500: 0.189560\n",
      "Loss after mini-batch  2000: 0.182727\n",
      "Loss after mini-batch  2500: 0.179026\n",
      "Loss after mini-batch  3000: 0.177351\n",
      "Loss after mini-batch  3500: 0.166677\n",
      "Loss after mini-batch  4000: 0.159628\n",
      "Loss after mini-batch  4500: 0.173670\n",
      "Loss after mini-batch  5000: 0.139981\n",
      "Loss after mini-batch  5500: 0.158186\n",
      "Loss after mini-batch  6000: 0.134531\n",
      "Starting epoch 3\n",
      "Loss after mini-batch   500: 0.127777\n",
      "Loss after mini-batch  1000: 0.120875\n",
      "Loss after mini-batch  1500: 0.134996\n",
      "Loss after mini-batch  2000: 0.126834\n",
      "Loss after mini-batch  2500: 0.112557\n",
      "Loss after mini-batch  3000: 0.113093\n",
      "Loss after mini-batch  3500: 0.109115\n",
      "Loss after mini-batch  4000: 0.119165\n",
      "Loss after mini-batch  4500: 0.106945\n",
      "Loss after mini-batch  5000: 0.094493\n",
      "Loss after mini-batch  5500: 0.108426\n",
      "Loss after mini-batch  6000: 0.095524\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  \n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "  \n",
    "    # Prepare CIFAR-10 dataset\n",
    "    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "  \n",
    "    # Initialize the ConvNet\n",
    "    convnet = ConvNet()\n",
    "    #convnet = ConvNet2()\n",
    "  \n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(convnet.parameters(), lr=1e-4)\n",
    "  \n",
    "    # Run the training loop\n",
    "    for epoch in range(0, 3): \n",
    "    \n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "    \n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "      \n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "      \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "      \n",
    "            # Perform forward pass\n",
    "            outputs = convnet(inputs)\n",
    "      \n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "      \n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "      \n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.6f' % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e28a20-1597-4217-ae98-6ee8ed7e48f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d64c28-21c9-429d-957b-12663129a643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
